{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üîß Treinamento de Detector de Ferramentas com YOLO v8\n",
        "\n",
        "**Notebook otimizado para Google Colab**\n",
        "\n",
        "Este notebook treina um modelo de detec√ß√£o de objetos usando YOLOv8 com pr√©-processamento avan√ßado de imagens.\n",
        "\n",
        "## üìã Pr√©-requisitos:\n",
        "1. Dataset no formato YOLO (train/valid/test com images/ e labels/)\n",
        "2. Google Colab com GPU habilitada (**Runtime > Change runtime type > GPU**)\n",
        "3. Dataset zipado pronto para upload\n",
        "\n",
        "## üöÄ Passos:\n",
        "1. Verificar GPU e ambiente\n",
        "2. Upload do dataset\n",
        "3. Pr√©-processamento das imagens\n",
        "4. Treinamento do modelo\n",
        "5. Valida√ß√£o e resultados\n",
        "6. Download do modelo treinado\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç PASSO 1: Verificar Ambiente e GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar se est√° no Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"‚úÖ Rodando no Google Colab\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"‚ö†Ô∏è N√£o est√° no Colab\")\n",
        "\n",
        "# Verificar GPU dispon√≠vel\n",
        "import torch\n",
        "print(f\"\\nüñ•Ô∏è PyTorch version: {torch.__version__}\")\n",
        "print(f\"üéÆ CUDA dispon√≠vel: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üìä GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ Mem√≥ria GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è GPU n√£o dispon√≠vel. V√° em: Runtime > Change runtime type > GPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ PASSO 2: Instalar Depend√™ncias\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instala as bibliotecas necess√°rias\n",
        "!pip install -q ultralytics pyyaml opencv-python matplotlib\n",
        "\n",
        "print(\"‚úÖ Depend√™ncias instaladas!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importar bibliotecas\n",
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import yaml\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"‚úÖ Bibliotecas importadas!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üíæ PASSO 3: Montar Google Drive (Opcional)\n",
        "\n",
        "**Se seu dataset estiver no Google Drive, execute esta c√©lula.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Montar Google Drive\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"‚úÖ Google Drive montado em /content/drive\")\n",
        "    print(\"\\nüìÇ Seus arquivos est√£o em: /content/drive/MyDrive/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì§ PASSO 4: Upload do Dataset\n",
        "\n",
        "**Execute a c√©lula abaixo para fazer upload do arquivo .zip**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload do arquivo .zip do dataset\n",
        "if IN_COLAB:\n",
        "    from google.colab import files\n",
        "    print(\"üì§ Fa√ßa upload do arquivo .zip do dataset...\")\n",
        "    uploaded = files.upload()\n",
        "    \n",
        "    # Pega o nome do arquivo\n",
        "    dataset_zip = list(uploaded.keys())[0]\n",
        "    print(f\"\\n‚úÖ Arquivo recebido: {dataset_zip}\")\n",
        "else:\n",
        "    # Se n√£o estiver no Colab, defina manualmente\n",
        "    dataset_zip = \"baseScrewdriver.zip\"  # ‚Üê Altere para o nome do seu arquivo\n",
        "\n",
        "# Alternativamente, copie do Google Drive (descomente se usar):\n",
        "# dataset_zip = \"/content/drive/MyDrive/seu_dataset.zip\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÇ PASSO 5: Descompactar e Verificar Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Descompactar o dataset\n",
        "ORIGINAL_DATA_DIR = \"/content/datasets_originais/\"\n",
        "\n",
        "print(f\"üì¶ Descompactando {dataset_zip}...\")\n",
        "!unzip -q {dataset_zip} -d {ORIGINAL_DATA_DIR}\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset descompactado em: {ORIGINAL_DATA_DIR}\")\n",
        "\n",
        "# Listar estrutura\n",
        "print(\"\\nüìÅ Estrutura do dataset:\")\n",
        "!ls -R {ORIGINAL_DATA_DIR} | head -20\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé® PASSO 6: Pr√©-Processamento das Imagens\n",
        "\n",
        "Aplica t√©cnicas avan√ßadas:\n",
        "- **Redimensionamento** (640x640)\n",
        "- **CLAHE** (equaliza√ß√£o de histograma adaptativa)\n",
        "- **Gaussian Blur** (redu√ß√£o de ru√≠do)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preProcessDataset(base_input_dir, base_output_dir, target_size=(640, 640)):\n",
        "    \"\"\"\n",
        "    Aplica pr√©-processamento em todo o dataset.\n",
        "    \n",
        "    T√©cnicas aplicadas:\n",
        "    1. Redimensionamento para tamanho padr√£o\n",
        "    2. CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
        "    3. Gaussian Blur para redu√ß√£o de ru√≠do\n",
        "    \"\"\"\n",
        "    print(\"\\nüé® Iniciando pr√©-processamento do dataset...\\n\")\n",
        "    \n",
        "    total_processed = 0\n",
        "    \n",
        "    # Itera sobre train, valid, test\n",
        "    for split in ['train', 'valid', 'test']:\n",
        "        input_images_path = os.path.join(base_input_dir, split, 'images')\n",
        "        input_labels_path = os.path.join(base_input_dir, split, 'labels')\n",
        "        \n",
        "        output_images_path = os.path.join(base_output_dir, split, 'images')\n",
        "        output_labels_path = os.path.join(base_output_dir, split, 'labels')\n",
        "        \n",
        "        # Criar pastas de sa√≠da\n",
        "        os.makedirs(output_images_path, exist_ok=True)\n",
        "        os.makedirs(output_labels_path, exist_ok=True)\n",
        "        \n",
        "        # Processar imagens\n",
        "        if os.path.exists(input_images_path):\n",
        "            images = [f for f in os.listdir(input_images_path) \n",
        "                     if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "            \n",
        "            print(f\"üìÇ Processando {split.upper()}: {len(images)} imagens\")\n",
        "            \n",
        "            for idx, filename in enumerate(images):\n",
        "                img_path = os.path.join(input_images_path, filename)\n",
        "                image = cv2.imread(img_path)\n",
        "                \n",
        "                if image is None:\n",
        "                    print(f\"   ‚ö†Ô∏è Erro ao ler: {filename}\")\n",
        "                    continue\n",
        "                \n",
        "                # ETAPA 1: Redimensionamento\n",
        "                processed_image = cv2.resize(image, target_size, interpolation=cv2.INTER_AREA)\n",
        "                \n",
        "                # ETAPA 2: CLAHE (Realce de Contraste)\n",
        "                lab = cv2.cvtColor(processed_image, cv2.COLOR_BGR2LAB)\n",
        "                l, a, b = cv2.split(lab)\n",
        "                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "                l_clahe = clahe.apply(l)\n",
        "                lab_clahe = cv2.merge((l_clahe, a, b))\n",
        "                processed_image = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
        "                \n",
        "                # ETAPA 3: Redu√ß√£o de Ru√≠do\n",
        "                processed_image = cv2.GaussianBlur(processed_image, (5, 5), 0)\n",
        "                \n",
        "                # Salvar imagem processada\n",
        "                output_path = os.path.join(output_images_path, filename)\n",
        "                cv2.imwrite(output_path, processed_image)\n",
        "                \n",
        "                total_processed += 1\n",
        "                \n",
        "                # Mostrar progresso a cada 50 imagens\n",
        "                if (idx + 1) % 50 == 0:\n",
        "                    print(f\"   üìä Progresso: {idx + 1}/{len(images)}\")\n",
        "        \n",
        "        # Copiar labels (n√£o precisam ser modificados)\n",
        "        if os.path.exists(input_labels_path):\n",
        "            labels = os.listdir(input_labels_path)\n",
        "            for label_file in labels:\n",
        "                shutil.copy(\n",
        "                    os.path.join(input_labels_path, label_file),\n",
        "                    output_labels_path\n",
        "                )\n",
        "            print(f\"   ‚úÖ {len(labels)} labels copiados\\n\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ Pr√©-processamento conclu√≠do!\")\n",
        "    print(f\"üìä Total de imagens processadas: {total_processed}\")\n",
        "    \n",
        "    return total_processed\n",
        "\n",
        "# Executar pr√©-processamento\n",
        "PROCESSED_DATA_DIR = \"/content/datasets_processados/\"\n",
        "total = preProcessDataset(ORIGINAL_DATA_DIR, PROCESSED_DATA_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù PASSO 7: Configurar data.yaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copiar e ajustar o data.yaml\n",
        "original_yaml_path = os.path.join(ORIGINAL_DATA_DIR, 'data.yaml')\n",
        "processed_yaml_path = os.path.join(PROCESSED_DATA_DIR, 'data.yaml')\n",
        "\n",
        "print(\"üìù Configurando data.yaml...\")\n",
        "\n",
        "with open(original_yaml_path, 'r') as f:\n",
        "    data_config = yaml.safe_load(f)\n",
        "\n",
        "# Atualizar caminhos para dados processados\n",
        "data_config['path'] = PROCESSED_DATA_DIR\n",
        "data_config['train'] = 'train/images'\n",
        "data_config['val'] = 'valid/images'\n",
        "data_config['test'] = 'test/images'\n",
        "\n",
        "# Salvar novo yaml\n",
        "with open(processed_yaml_path, 'w') as f:\n",
        "    yaml.dump(data_config, f)\n",
        "\n",
        "print(f\"\\n‚úÖ Arquivo data.yaml criado!\")\n",
        "print(f\"\\nüìã Classes: {data_config.get('names', [])}\")\n",
        "print(f\"üî¢ Total: {data_config.get('nc', 0)} classes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ PASSO 8: Treinamento do Modelo\n",
        "\n",
        "**IMPORTANTE:** Este processo pode levar de **30 minutos a 2 horas** dependendo:\n",
        "- Tamanho do dataset\n",
        "- N√∫mero de √©pocas\n",
        "- GPU dispon√≠vel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "print(\"üöÄ Iniciando treinamento do modelo YOLO...\\n\")\n",
        "print(\"‚è±Ô∏è Isso pode levar algum tempo. Aguarde...\\n\")\n",
        "\n",
        "# Carregar modelo pr√©-treinado\n",
        "model = YOLO('yolov8n.pt')  # Nano (mais r√°pido)\n",
        "# model = YOLO('yolov8s.pt')  # Small (mais preciso)\n",
        "# model = YOLO('yolov8m.pt')  # Medium (ainda mais preciso)\n",
        "\n",
        "print(\"‚úÖ Modelo YOLOv8 Nano carregado\\n\")\n",
        "\n",
        "# Configura√ß√£o do treinamento\n",
        "results = model.train(\n",
        "    data=processed_yaml_path,      # Caminho para data.yaml\n",
        "    epochs=50,                      # N√∫mero de √©pocas\n",
        "    imgsz=640,                      # Tamanho da imagem\n",
        "    batch=16,                       # Tamanho do batch\n",
        "    project='meus_treinamentos',    # Nome do projeto\n",
        "    name='detector_ferramentas_v1', # Nome do experimento\n",
        "    patience=10,                    # Early stopping\n",
        "    save=True,                      # Salvar checkpoints\n",
        "    device=0 if torch.cuda.is_available() else 'cpu',  # GPU ou CPU\n",
        "    workers=2,                      # N√∫mero de workers\n",
        "    verbose=True                    # Mostrar logs detalhados\n",
        ")\n",
        "\n",
        "print(\"\\nüéâ Treinamento conclu√≠do!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä PASSO 9: Visualizar Resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Caminho dos resultados\n",
        "results_dir = \"/content/meus_treinamentos/detector_ferramentas_v1\"\n",
        "\n",
        "print(\"üìä Resultados do Treinamento:\\n\")\n",
        "\n",
        "# Mostrar gr√°ficos de treinamento\n",
        "plots = [\n",
        "    'results.png',           # M√©tricas gerais\n",
        "    'confusion_matrix.png',  # Matriz de confus√£o\n",
        "    'val_batch0_pred.jpg',   # Predi√ß√µes no validation\n",
        "]\n",
        "\n",
        "for plot in plots:\n",
        "    plot_path = os.path.join(results_dir, plot)\n",
        "    if os.path.exists(plot_path):\n",
        "        print(f\"\\nüìà {plot}:\")\n",
        "        display(Image(filename=plot_path))\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è {plot} n√£o encontrado\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ PASSO 10: Validar Modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar o melhor modelo treinado\n",
        "best_model_path = os.path.join(results_dir, 'weights', 'best.pt')\n",
        "\n",
        "if os.path.exists(best_model_path):\n",
        "    print(f\"‚úÖ Modelo encontrado: {best_model_path}\\n\")\n",
        "    \n",
        "    # Carregar modelo\n",
        "    model_trained = YOLO(best_model_path)\n",
        "    \n",
        "    # Validar no dataset de teste\n",
        "    print(\"üß™ Validando modelo no dataset de teste...\\n\")\n",
        "    metrics = model_trained.val(data=processed_yaml_path, split='test')\n",
        "    \n",
        "    print(\"\\nüìä M√©tricas de Valida√ß√£o:\")\n",
        "    print(f\"   mAP50: {metrics.box.map50:.4f}\")\n",
        "    print(f\"   mAP50-95: {metrics.box.map:.4f}\")\n",
        "    print(f\"   Precision: {metrics.box.mp:.4f}\")\n",
        "    print(f\"   Recall: {metrics.box.mr:.4f}\")\n",
        "else:\n",
        "    print(\"‚ùå Modelo n√£o encontrado!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ PASSO 11: Testar em Imagens de Exemplo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testar em imagens de exemplo\n",
        "test_images_dir = os.path.join(PROCESSED_DATA_DIR, 'test', 'images')\n",
        "\n",
        "if os.path.exists(test_images_dir):\n",
        "    test_images = [f for f in os.listdir(test_images_dir) if f.endswith(('.jpg', '.jpeg', '.png'))][:3]\n",
        "    \n",
        "    if test_images:\n",
        "        print(\"üéØ Testando modelo em imagens de exemplo...\\n\")\n",
        "        \n",
        "        for img_name in test_images:\n",
        "            img_path = os.path.join(test_images_dir, img_name)\n",
        "            \n",
        "            # Fazer predi√ß√£o\n",
        "            results = model_trained.predict(\n",
        "                source=img_path,\n",
        "                conf=0.5,  # Confian√ßa m√≠nima 50%\n",
        "                save=True,\n",
        "                project='predicoes_teste',\n",
        "                name='resultados'\n",
        "            )\n",
        "            \n",
        "            print(f\"\\n‚úÖ {img_name}:\")\n",
        "            for r in results:\n",
        "                print(f\"   Detectados: {len(r.boxes)} objetos\")\n",
        "                for box in r.boxes:\n",
        "                    cls = int(box.cls[0])\n",
        "                    conf = float(box.conf[0])\n",
        "                    class_name = model_trained.names[cls]\n",
        "                    print(f\"   - {class_name}: {conf:.2%}\")\n",
        "        \n",
        "        # Mostrar resultados\n",
        "        print(\"\\nüñºÔ∏è Imagens com detec√ß√µes:\")\n",
        "        pred_dir = \"/content/predicoes_teste/resultados\"\n",
        "        if os.path.exists(pred_dir):\n",
        "            for img in os.listdir(pred_dir):\n",
        "                if img.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    display(Image(filename=os.path.join(pred_dir, img)))\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Nenhuma imagem de teste encontrada\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üíæ PASSO 12: Download do Modelo Treinado\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download do modelo treinado\n",
        "if IN_COLAB and os.path.exists(best_model_path):\n",
        "    from google.colab import files\n",
        "    \n",
        "    print(\"üíæ Preparando download do modelo...\\n\")\n",
        "    \n",
        "    # Copiar para um nome mais amig√°vel\n",
        "    model_download_path = \"/content/modelo_detector_ferramentas.pt\"\n",
        "    shutil.copy(best_model_path, model_download_path)\n",
        "    \n",
        "    print(\"üì• Fazendo download do modelo...\")\n",
        "    files.download(model_download_path)\n",
        "    \n",
        "    print(\"\\n‚úÖ Download conclu√≠do!\")\n",
        "    print(f\"üìä Tamanho: {os.path.getsize(model_download_path) / (1024*1024):.2f} MB\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Para download manual, localize:\")\n",
        "    print(f\"   {best_model_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üíæ PASSO 13: Salvar no Google Drive (Opcional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Salvar modelo no Google Drive\n",
        "if IN_COLAB:\n",
        "    save_to_drive = input(\"üíæ Salvar modelo no Google Drive? (s/n): \")\n",
        "    \n",
        "    if save_to_drive.lower() == 's':\n",
        "        # Criar pasta no Drive\n",
        "        drive_save_path = \"/content/drive/MyDrive/Modelos_YOLO/\"\n",
        "        os.makedirs(drive_save_path, exist_ok=True)\n",
        "        \n",
        "        # Copiar modelo\n",
        "        final_path = os.path.join(drive_save_path, \"detector_ferramentas_best.pt\")\n",
        "        shutil.copy(best_model_path, final_path)\n",
        "        \n",
        "        print(f\"\\n‚úÖ Modelo salvo no Drive: {final_path}\")\n",
        "        \n",
        "        # Tamb√©m salvar resultados\n",
        "        results_zip = \"/content/resultados_treinamento.zip\"\n",
        "        !zip -r -q {results_zip} {results_dir}\n",
        "        shutil.copy(results_zip, drive_save_path)\n",
        "        print(f\"‚úÖ Resultados salvos: {drive_save_path}resultados_treinamento.zip\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã RESUMO FINAL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" \"*20 + \"üìä RESUMO DO TREINAMENTO\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset:\")\n",
        "print(f\"   - Imagens processadas: {total} imagens\")\n",
        "print(f\"   - Classes: {data_config.get('nc', 0)}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Modelo:\")\n",
        "print(f\"   - Arquitetura: YOLOv8 Nano\")\n",
        "print(f\"   - √âpocas: 50\")\n",
        "print(f\"   - Caminho: {best_model_path}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Pr√≥ximos Passos:\")\n",
        "print(f\"   1. Baixe o modelo best.pt\")\n",
        "print(f\"   2. Use no seu projeto Flask/Python\")\n",
        "print(f\"   3. Substitua o modelo no Roboflow\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\\nüéâ Treinamento conclu√≠do com sucesso!\")\n",
        "print(\"=\"*70 + \"\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
